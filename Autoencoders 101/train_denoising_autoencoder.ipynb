{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_denoising_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ishkxEOJo4Kq"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "class ConvAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, filters=(32, 64), latent_dim=16):\n",
        "\n",
        "    # initialize input shape to be channels last along with channels dimension itself\n",
        "    input_shape = (height, width, depth)\n",
        "    chan_dim = -1\n",
        "\n",
        "    # define input to encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # loop over the number of filters\n",
        "    for f in filters:\n",
        "      # apply CONV => RELU => BN operations\n",
        "      x = Conv2D(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # flatten the network and then consturct our latent vector\n",
        "    volume_size = K.int_shape(x)\n",
        "    x = Flatten()(x)\n",
        "    latent = Dense(latent_dim)(x)\n",
        "\n",
        "    # build the encoder model\n",
        "    encoder = Model(inputs, latent, name='encoder')\n",
        "\n",
        "    # start building the decoder model which will accept output of encoder as its input\n",
        "    latent_input = Input(shape=(latent_dim,))\n",
        "    x = Dense(np.prod(volume_size[1:]))(latent_input)\n",
        "    x = Reshape((volume_size[1], volume_size[2], volume_size[3]))(x)\n",
        "\n",
        "    # loop over number of filters again but this time in reverse order\n",
        "    for f in filters[::-1]:\n",
        "      \n",
        "      # apply a Conv_transpose => RELU => BN operation\n",
        "      x = Conv2DTranspose(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # apply a single Conv_Transpose layer used to recover the original depth of image\n",
        "    x = Conv2DTranspose(depth, (3, 3), padding='same')(x)\n",
        "    outputs = Activation('sigmoid')(x)\n",
        "\n",
        "    # build decoder model\n",
        "    decoder = Model(latent_input, outputs, name='decoder')\n",
        "\n",
        "    # autoencoder is encoder + decoder\n",
        "    autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "\n",
        "    return (encoder, decoder, autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# denoising autoencoders\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "num_samples = 8          # The number of output samples for visualization\n",
        "output = 'output.png'    # The path the output visualization image\n",
        "plot = 'plot.png'        # The path to our matplotlib output plot\n",
        "\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "\n",
        "# load mnist dataset\n",
        "print('[INFO] loading MNIST dataset...')\n",
        "((trainX, _), (testX, _)) = mnist.load_data()\n",
        "\n",
        "# add channel dimension to every image in dataset and scale pixel intensities to range [0, 1]\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "trainX = trainX.astype('float32')/255.0\n",
        "testX = testX.astype('float32')/255.0\n",
        "\n",
        "# sample noise from a random normal distribution centered at 0.5 (since our image lie in the \n",
        "# range [0, 1]) and a standard deviation of 0.5\n",
        "train_noise = np.random.normal(loc=0.5, scale=0.5, size=trainX.shape)\n",
        "test_noise = np.random.normal(loc=0.5, scale=0.5, size=testX.shape)\n",
        "trainX_noisy = np.clip(trainX+train_noise, 0, 1)\n",
        "testX_noisy = np.clip(testX+test_noise, 0, 1)\n",
        "\n",
        "# construct our Conv autoencoder\n",
        "print('[INFO] building autoencoder...')\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "autoencoder.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "# train convolution autoencoder\n",
        "H=autoencoder.fit(trainX_noisy, trainX, validation_data=(testX_noisy, testX), epochs=epochs, \n",
        "                    batch_size=batch_size)\n",
        "\n",
        "# construct a plot that plots and saves training history\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use('ggplot')\n",
        "plt.figure()\n",
        "plt.plot(N, H.history['loss'], label='train_loss')\n",
        "plt.plot(N, H.history['val_loss'], label='validation_loss')\n",
        "plt.title('Training loss and accuracy')\n",
        "plt.xlabel('Epochs #')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.legend(loc='lower left')\n",
        "plt.savefig(plot)\n",
        "\n",
        "# use convautoencoders to make predictions on test images\n",
        "print('[INFO] Making predictions...')\n",
        "decode = autoencoder.predict(testX_noisy)\n",
        "outputs = None\n",
        "\n",
        "# loop over the number of output samples\n",
        "for i in range(0, num_samples):\n",
        "  \n",
        "  # grab original image and reconstructed image\n",
        "  original = (testX_noisy[i]*255).astype('uint8')\n",
        "  recon = (decode[i]*255).astype('uint8')\n",
        "\n",
        "  # stack original and reconstructed image side by side\n",
        "  output = np.hstack([original, recon])\n",
        "\n",
        "  # it output array is empty initialize it as current side by side image display\n",
        "  if outputs is None:\n",
        "    outputs = output\n",
        "    # otherwise vertically stack outputs\n",
        "  else:\n",
        "    outputs = np.vstack([outputs, output])\n",
        "\n",
        "# save output image to disk\n",
        "cv.imwrite('output.png', outputs)"
      ],
      "metadata": {
        "id": "nZ0Q-8OZuIMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3feffc91-c3bb-4056-be2e-ec3c94a2a58c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n",
            "[INFO] building autoencoder...\n",
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 28s 9ms/step - loss: 0.0280 - val_loss: 0.0192\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0189 - val_loss: 0.0196\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0178 - val_loss: 0.0182\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0172 - val_loss: 0.0171\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0168 - val_loss: 0.0173\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0165 - val_loss: 0.0167\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0163 - val_loss: 0.0166\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0160 - val_loss: 0.0163\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0159 - val_loss: 0.0163\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0157 - val_loss: 0.0159\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0156 - val_loss: 0.0167\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0154 - val_loss: 0.0160\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0154 - val_loss: 0.0160\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0152 - val_loss: 0.0160\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0152 - val_loss: 0.0165\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0151 - val_loss: 0.0162\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0150 - val_loss: 0.0162\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0149 - val_loss: 0.0158\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0149 - val_loss: 0.0158\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0148 - val_loss: 0.0156\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0148 - val_loss: 0.0155\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0147 - val_loss: 0.0162\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0146 - val_loss: 0.0157\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0146 - val_loss: 0.0155\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0146 - val_loss: 0.0156\n",
            "[INFO] Making predictions...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2BknYdgN3p_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}