{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anomaly_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFFXoWpjK97A"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "class ConvAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, filters=(32, 64), latent_dim=16):\n",
        "\n",
        "    # initialize input shape to be channels last along with channels dimension itself\n",
        "    input_shape = (height, width, depth)\n",
        "    chan_dim = -1\n",
        "\n",
        "    # define input to encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # loop over the number of filters\n",
        "    for f in filters:\n",
        "      # apply CONV => RELU => BN operations\n",
        "      x = Conv2D(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # flatten the network and then consturct our latent vector\n",
        "    volume_size = K.int_shape(x)\n",
        "    x = Flatten()(x)\n",
        "    latent = Dense(latent_dim)(x)\n",
        "\n",
        "    # build the encoder model\n",
        "    encoder = Model(inputs, latent, name='encoder')\n",
        "\n",
        "    # start building the decoder model which will accept output of encoder as its input\n",
        "    latent_input = Input(shape=(latent_dim,))\n",
        "    x = Dense(np.prod(volume_size[1:]))(latent_input)\n",
        "    x = Reshape((volume_size[1], volume_size[2], volume_size[3]))(x)\n",
        "\n",
        "    # loop over number of filters again but this time in reverse order\n",
        "    for f in filters[::-1]:\n",
        "      \n",
        "      # apply a Conv_transpose => RELU => BN operation\n",
        "      x = Conv2DTranspose(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # apply a single Conv_Transpose layer used to recover the original depth of image\n",
        "    x = Conv2DTranspose(depth, (3, 3), padding='same')(x)\n",
        "    outputs = Activation('sigmoid')(x)\n",
        "\n",
        "    # build decoder model\n",
        "    decoder = Model(latent_input, outputs, name='decoder')\n",
        "\n",
        "    # autoencoder is encoder + decoder\n",
        "    autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "\n",
        "    return (encoder, decoder, autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training autoencoders\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# Since we are doing unsupervised learning so we will build an unsupervised dataset\n",
        "def build_unsupervised_dataset(data, labels, valid_label=1, anomaly_label=3, \n",
        "                               contam=0.01, seed=42):\n",
        "  # grab all indexes of supplied class label that are truly that particular label\n",
        "  # then grab the indexes of image labels that will serve as our anomalies\n",
        "  valid_idxs = np.where(labels==valid_label)[0]\n",
        "  anomaly_idxs = np.where(labels==anomaly_label)[0]\n",
        "\n",
        "  # randomly shuffle both set of labels\n",
        "  random.shuffle(valid_idxs)\n",
        "  random.shuffle(anomaly_idxs)\n",
        "\n",
        "  # compute the total number of anomaly data points to select\n",
        "  i = int(len(valid_idxs) * contam)\n",
        "  anomaly_idxs = anomaly_idxs[:i]\n",
        "\n",
        "  # use numpy array indexing to extract both valid images and anomaly images\n",
        "  valid_images = data[valid_idxs]\n",
        "  anomaly_images = data[anomaly_idxs]\n",
        "\n",
        "  # stack the valid images and anomaly images together to form a single data matrix and then\n",
        "  # shuffle the rows\n",
        "  images = np.vstack([valid_images, anomaly_images])\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(images)\n",
        "\n",
        "  return images\n",
        "\n",
        "# Function to help visualize predictions made by unsupervised autoencoder \n",
        "def visualize_prediction(decode, gt, samples=10):\n",
        "  # initialize list of output images\n",
        "  outputs = None\n",
        "\n",
        "  # loop over our number of output samples\n",
        "  for i in range(0, samples):\n",
        "    # grab original image and reconstructed image\n",
        "    original = (gt[i]*255).astype('uint8')\n",
        "    recon = (decode[i]*255).astype('uint8')\n",
        "\n",
        "    # stack original and reconstructed images side by side\n",
        "    output = np.hstack([original, recon])\n",
        "\n",
        "    # if the output array is empty, initialize it as the current side-by-side image display\n",
        "    if outputs is None:\n",
        "      outputs = output\n",
        "\n",
        "    # otherwise vertically stack the output\n",
        "    else:\n",
        "      outputs = np.vstack([outputs, output])\n",
        "\n",
        "  return outputs\n",
        "\n",
        "# arguments\n",
        "dataset = 'output/images.pickle'       # path to output dataset file\n",
        "model_name = 'output/autoencoder.model'         # path to our output trained autoencoder\n",
        "visu = \"recon_vis.png\"\n",
        "plot = \"plot.png\"\n",
        "epochs = 20\n",
        "init_lr = 1e-3\n",
        "batch_size = 32\n",
        "\n",
        "# load mnist dataset\n",
        "print('[INFO] loading MNIST dataset...')\n",
        "((trainx, trainy), (testx, testy)) = mnist.load_data()\n",
        "\n",
        "# build our unsupervised dataset with small amount of contamination added to it\n",
        "print('[INFO] creating unsupervised dataset...')\n",
        "images = build_unsupervised_dataset(trainx, trainy, valid_label=1, anomaly_label=3, contam=0.01)\n",
        "\n",
        "# add a channel dimension to every image in dataset, and scale pixel intensities to range [0, 1]\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "images = images.astype('float32')/255.0\n",
        "\n",
        "# construct training and testing split\n",
        "(trainX, testX) = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# construct our Conv autoencoder\n",
        "print('[INFO] building autoencoder...')\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(learning_rate=init_lr, decay=init_lr/epochs)\n",
        "autoencoder.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "# train convolution autoencoder\n",
        "H=autoencoder.fit(trainX, trainX, validation_data=(testX, testX), epochs=epochs, \n",
        "                    batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "dRokUMz-Nxfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278837d9-3f41-4c38-9660-955d5ea71111"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "[INFO] creating unsupervised dataset...\n",
            "[INFO] building autoencoder...\n",
            "Epoch 1/20\n",
            "171/171 [==============================] - 11s 28ms/step - loss: 0.0368 - val_loss: 0.0434\n",
            "Epoch 2/20\n",
            "171/171 [==============================] - 3s 20ms/step - loss: 0.0101 - val_loss: 0.0278\n",
            "Epoch 3/20\n",
            "171/171 [==============================] - 3s 20ms/step - loss: 0.0040 - val_loss: 0.0101\n",
            "Epoch 4/20\n",
            "171/171 [==============================] - 4s 21ms/step - loss: 0.0032 - val_loss: 0.0033\n",
            "Epoch 5/20\n",
            "171/171 [==============================] - 4s 21ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 6/20\n",
            "171/171 [==============================] - 4s 23ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 7/20\n",
            "171/171 [==============================] - 3s 19ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 8/20\n",
            "171/171 [==============================] - 3s 19ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 9/20\n",
            "171/171 [==============================] - 3s 18ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 10/20\n",
            "171/171 [==============================] - 3s 18ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 11/20\n",
            "171/171 [==============================] - 3s 18ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 12/20\n",
            "171/171 [==============================] - 3s 18ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 13/20\n",
            "171/171 [==============================] - 3s 18ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 14/20\n",
            "171/171 [==============================] - 3s 16ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 15/20\n",
            "171/171 [==============================] - 3s 15ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 16/20\n",
            "171/171 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 17/20\n",
            "171/171 [==============================] - 2s 12ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 18/20\n",
            "171/171 [==============================] - 2s 11ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 19/20\n",
            "171/171 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 20/20\n",
            "171/171 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use convolutional autoencoder to make predictions on testing images, construct the visualization, \n",
        "# and then save it to disk\n",
        "print('[INFO] making predictions...')\n",
        "decoded = autoencoder.predict(testX)\n",
        "vis = visualize_prediction(decoded, testX)\n",
        "cv.imwrite(visu, vis)\n",
        "\n",
        "# construct a plot that plots and saves training history\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use('ggplot')\n",
        "plt.figure()\n",
        "plt.plot(N, H.history['loss'], label='train_loss')\n",
        "plt.plot(N, H.history['val_loss'], label='validation_loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs #')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower left')\n",
        "plt.savefig(plot)\n",
        "\n",
        "# serialize image data to disk\n",
        "print('[INFO] saving image data...')\n",
        "f = open(dataset, 'wb')\n",
        "f.write(pickle.dumps(images))\n",
        "f.close()\n",
        "\n",
        "# serialize autoencoder model to disk\n",
        "autoencoder.save(model_name, save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L03DbCpgxAYz",
        "outputId": "4c87d0de-9c83-4d82-9e81-7324a79f9a11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] making predictions...\n",
            "[INFO] saving image data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding anomalies\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import pickle\n",
        "\n",
        "dataset = 'output/images.pickle'\n",
        "model = 'output/autoencoder.model'\n",
        "quantile = 0.999\n",
        "\n",
        "# load model and image data from disk\n",
        "print('[INFO] loading autoencoder model and image data...')\n",
        "autoencoder = load_model(model)\n",
        "images = pickle.loads(open(dataset, 'rb').read())\n",
        "\n",
        "# make predictions on our image data and initialize list of reconstruction errors\n",
        "decoded = autoencoder.predict(images)\n",
        "errors = []\n",
        "\n",
        "# loop over the original image and their corresponding reconstructions\n",
        "for (image, recon) in zip(images, decoded):\n",
        "  \n",
        "  # compute mean squared error between ground-truth image and reconstructed image and add it to\n",
        "  # list of errors\n",
        "  mse = np.mean((image - recon)**2)\n",
        "  errors.append(mse)\n",
        "\n",
        "# compute q-thquantile of errors which serves as our threshold to identify anomalies -- any data\n",
        "# point that our model reconstructed with > threshold error will be marked as outlier\n",
        "thresh = np.quantile(errors, quantile)\n",
        "idxs = np.where(np.array(errors)>=thresh)[0]\n",
        "print(f'[INFO] MSE threshold: {thresh}')\n",
        "print(f'[INFO] outliers found: {len(idxs)}')\n",
        "\n",
        "# initialize the outputs array\n",
        "outputs = None\n",
        "\n",
        "# loop over the indexes of images with a high mean squared error term\n",
        "for i in idxs:\n",
        "  \n",
        "  # grab original image and reconstructed image side-by-side\n",
        "  original = (images[i]*255).astype('uint8')\n",
        "  recon = (decoded[i]*255).astype('uint8')\n",
        "\n",
        "  # stack original and reconstructed images side by side\n",
        "  output = np.hstack([original, recon])\n",
        "\n",
        "  # if the output array is empty, initialize it as the current side-by-side image display\n",
        "  if outputs is None:\n",
        "    outputs = output\n",
        "\n",
        "  # otherwise vertically stack the output\n",
        "  else:\n",
        "    outputs = np.vstack([outputs, output])\n",
        "\n",
        "# show output visualization\n",
        "cv2_imshow(outputs)"
      ],
      "metadata": {
        "id": "tYHs0VmSeaAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "592ed2f0-e5dc-4e80-b9a4-70d027e04f58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading autoencoder model and image data...\n",
            "[INFO] MSE threshold: 0.02453741629421712\n",
            "[INFO] outliers found: 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=56x196 at 0x7F9E2D01D790>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j3XFB7TsLIDe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}