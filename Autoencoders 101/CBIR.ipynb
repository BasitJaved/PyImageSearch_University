{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBIR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n6OBc8AvaqCF"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "class ConvAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, filters=(32, 64), latent_dim=16):\n",
        "\n",
        "    # initialize input shape to be channels last along with channels dimension itself\n",
        "    input_shape = (height, width, depth)\n",
        "    chan_dim = -1\n",
        "\n",
        "    # define input to encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # loop over the number of filters\n",
        "    for f in filters:\n",
        "      # apply CONV => RELU => BN operations\n",
        "      x = Conv2D(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # flatten the network and then consturct our latent vector\n",
        "    volume_size = K.int_shape(x)\n",
        "    x = Flatten()(x)\n",
        "    latent = Dense(latent_dim, name='encoder')(x)\n",
        "\n",
        "    # start building the decoder model which will accept output of encoder as its input\n",
        "    x = Dense(np.prod(volume_size[1:]))(latent)\n",
        "    x = Reshape((volume_size[1], volume_size[2], volume_size[3]))(x)\n",
        "\n",
        "    # loop over number of filters again but this time in reverse order\n",
        "    for f in filters[::-1]:\n",
        "      \n",
        "      # apply a Conv_transpose => RELU => BN operation\n",
        "      x = Conv2DTranspose(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # apply a single Conv_Transpose layer used to recover the original depth of image\n",
        "    x = Conv2DTranspose(depth, (3, 3), padding='same')(x)\n",
        "    outputs = Activation('sigmoid', name='decoder')(x)\n",
        "\n",
        "    # autoencoder is encoder + decoder\n",
        "    autoencoder = Model(inputs, outputs, name='autoencoder')\n",
        "\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training autoencoders\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "# Function to help visualize predictions made by unsupervised autoencoder \n",
        "def visualize_prediction(decode, gt, samples=10):\n",
        "  # initialize list of output images\n",
        "  outputs = None\n",
        "\n",
        "  # loop over our number of output samples\n",
        "  for i in range(0, samples):\n",
        "    # grab original image and reconstructed image\n",
        "    original = (gt[i]*255).astype('uint8')\n",
        "    recon = (decode[i]*255).astype('uint8')\n",
        "\n",
        "    # stack original and reconstructed images side by side\n",
        "    output = np.hstack([original, recon])\n",
        "\n",
        "    # if the output array is empty, initialize it as the current side-by-side image display\n",
        "    if outputs is None:\n",
        "      outputs = output\n",
        "\n",
        "    # otherwise vertically stack the output\n",
        "    else:\n",
        "      outputs = np.vstack([outputs, output])\n",
        "\n",
        "  return outputs\n",
        "\n",
        "# arguments\n",
        "model_name = 'output/autoencoder.model'         # path to our output trained autoencoder\n",
        "visu = \"recon_vis.png\"\n",
        "plot = \"plot.png\"\n",
        "epochs = 20\n",
        "init_lr = 1e-3\n",
        "batch_size = 32\n",
        "\n",
        "# load mnist dataset\n",
        "print('[INFO] loading MNIST dataset...')\n",
        "((trainX, _), (testX, _)) = mnist.load_data()\n",
        "\n",
        "# add channel dimension to every image in dataset and scale pixel intensities to range [0, 1]\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "trainX = trainX.astype('float32')/255.0\n",
        "testX = testX.astype('float32')/255.0\n",
        "\n",
        "# construct our Conv autoencoder\n",
        "print('[INFO] building autoencoder...')\n",
        "autoencoder = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(learning_rate=init_lr, decay=init_lr/epochs)\n",
        "autoencoder.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "# train convolution autoencoder\n",
        "H=autoencoder.fit(trainX, trainX, validation_data=(testX, testX), epochs=epochs, \n",
        "                    batch_size=batch_size)\n",
        "\n",
        "# use the convolution auto encoder to make the predictions on the testing images, construct the \n",
        "# visualizations and save it to disk\n",
        "decoded = autoencoder.predict(testX)\n",
        "vis = visualize_prediction(decoded, testX)\n",
        "cv.imwrite(visu, vis)\n",
        "\n",
        "# construct a plot that plots and saves training history\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use('ggplot')\n",
        "plt.figure()\n",
        "plt.plot(N, H.history['loss'], label='train_loss')\n",
        "plt.plot(N, H.history['val_loss'], label='validation_loss')\n",
        "plt.title('Training loss and accuracy')\n",
        "plt.xlabel('Epochs #')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.legend(loc='lower left')\n",
        "plt.savefig(plot)\n",
        "\n",
        "# serialize the autoencoder model to disk\n",
        "print('[INFO] saving autoencoder')\n",
        "autoencoder.save(model_name, save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_clCw1VdOBn",
        "outputId": "5502f18e-92c9-4b39-cacf-4d072c61ae41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "[INFO] building autoencoder...\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 20s 5ms/step - loss: 0.0180 - val_loss: 0.0110\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0101 - val_loss: 0.0095\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0091 - val_loss: 0.0089\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0086 - val_loss: 0.0083\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0081 - val_loss: 0.0079\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0075\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0074 - val_loss: 0.0078\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0073 - val_loss: 0.0073\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0071 - val_loss: 0.0074\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0070 - val_loss: 0.0071\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0069 - val_loss: 0.0070\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0068 - val_loss: 0.0070\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0067 - val_loss: 0.0069\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0066 - val_loss: 0.0069\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0066 - val_loss: 0.0068\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0065 - val_loss: 0.0068\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0065 - val_loss: 0.0067\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0064 - val_loss: 0.0067\n",
            "[INFO] saving autoencoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing images\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "model_path = 'output/autoencoder.model'   # path to trained autoencoder model\n",
        "index_path = 'output/index.pickle'        # path to output features index file\n",
        "\n",
        "# load mnist dataset\n",
        "print('[INFO] loading MNIST dataset...')\n",
        "((trainX, _), (testX, _)) = mnist.load_data()\n",
        "\n",
        "# add channel dimension to every image in dataset and scale pixel intensities to range [0, 1]\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "trainX = trainX.astype('float32')/255.0\n",
        "\n",
        "# load encoder model from disk\n",
        "print('[INFO] loading autoencoder model...')\n",
        "autoencoder = load_model(model_path)\n",
        "\n",
        "# create the auto encoder model which consists of just the encoder portion of model\n",
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder').output)\n",
        "\n",
        "# quantify the contents of our input images using encoder\n",
        "print('[INFO] encoding images...')\n",
        "features = encoder.predict(trainX)\n",
        "\n",
        "# construct a dictionary that maps index of MNIST training image to its corresponding latent-space\n",
        "# representation\n",
        "indexes = list(range(0, trainX.shape[0]))\n",
        "data = {'indexes': indexes, 'features' : features}\n",
        "\n",
        "# write data dictionary to disk\n",
        "print('[INFO] Saving index...')\n",
        "f = open(index_path, 'wb')\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BiZbJJWfVSh",
        "outputId": "2d03f397-ab7a-44a5-ead8-dec47c2b8465"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "[INFO] loading autoencoder model...\n",
            "[INFO] encoding images...\n",
            "[INFO] Saving index...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l9cwFlflm9AL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}