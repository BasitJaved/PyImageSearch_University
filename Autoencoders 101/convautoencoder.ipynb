{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convautoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ishkxEOJo4Kq"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "class ConvAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, filters=(32, 64), latent_dim=16):\n",
        "\n",
        "    # initialize input shape to be channels last along with channels dimension itself\n",
        "    input_shape = (height, width, depth)\n",
        "    chan_dim = -1\n",
        "\n",
        "    # define input to encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # loop over the number of filters\n",
        "    for f in filters:\n",
        "      # apply CONV => RELU => BN operations\n",
        "      x = Conv2D(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "    # flatten the network and then consturct our latent vector\n",
        "    volume_size = K.int_shape(x)\n",
        "    x = Flatten()(x)\n",
        "    latent = Dense(latent_dim)(x)\n",
        "\n",
        "    # build the encoder model\n",
        "    encoder = Model(inputs, latent, name='encoder')\n",
        "\n",
        "    # start building the decoder model which will accept output of encoder as its input\n",
        "    latent_input = Input(shape=(latent_dim,))\n",
        "    x = Dense(np.prod(volume_size[1:]))(latent_input)\n",
        "    x = Reshape((volume_size[1], volume_size[2], volume_size[3]))(x)\n",
        "\n",
        "    # loop over number of filters again but this time in reverse order\n",
        "    for f in filters[::-1]:\n",
        "      \n",
        "      # apply a Conv_transpose => RELU => BN operation\n",
        "      x = Conv2DTranspose(f, (3, 3), strides=2, padding='same')(x)\n",
        "      x = LeakyReLU(alpha=0.2)(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "\n",
        "      # apply a single Conv_Transpose layer used to recover the original depth of image\n",
        "      x = Conv2DTranspose(depth, (3, 3), padding='same')(x)\n",
        "      outputs = Activation('sigmoid')(x)\n",
        "\n",
        "      # build decoder model\n",
        "      decoder = Model(latent_input, outputs, name='decoder')\n",
        "\n",
        "      # autoencoder is encoder + decoder\n",
        "      autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "\n",
        "      return (encoder, decoder, autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nZ0Q-8OZuIMe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}