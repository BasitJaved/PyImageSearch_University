{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85895b56-0f50-4111-8b1b-bd7f0ebcf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "import os\n",
    "\n",
    "# specify the shape of input for our network\n",
    "image_shape = (28, 28, 1)\n",
    "\n",
    "# specify the batch size and number of epochs\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "# define path to base output directory\n",
    "base_output = 'output'\n",
    "\n",
    "# use base output path to derive the path to serialized model along with training history plot\n",
    "model_path = os.path.sep.join([base_output, 'contrastlive_siamese_model'])\n",
    "plot_path = os.path.sep.join([base_output, 'contrastlive_plot.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e97ac5-a1b7-4316-87ed-f6762eef55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "def build_siamese_model(input_shape, embedding_dim=48):\n",
    "    # specify inputs for feature extractor network\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # define first set of CONV=>RELU=>POOL=>Dropout layers\n",
    "    x = Conv2D(64, (2, 2), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # define second set of CONV=>RELU=>POOL=>Dropout layers\n",
    "    x = Conv2D(64, (2, 2), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # prepare the final outputs\n",
    "    pooled_output = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(embedding_dim)(pooled_output)\n",
    "\n",
    "    # build the model\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # return model to calling function\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acff2d26-535e-4092-87aa-bb89403c9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "#imports\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# image pair generation\n",
    "def make_pairs(images, labels):\n",
    "    # initialize 2 empty lists to hold (image, image) pairs and \n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    # calculate the total number of classes present in dataset and then build a list of\n",
    "    # indexes for each class label that provides indexes for all examples with a given label\n",
    "    num_classes = len(np.unique(labels))\n",
    "    idx = [np.where(labels==i)[0] for i in range(0, num_classes)]\n",
    "    \n",
    "    # loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "        # grab the current image and label belonging to current iteration\n",
    "        current_image = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        \n",
    "        # randomly pic an image that belong to same class label\n",
    "        idxB = np.random.choice(idx[label])\n",
    "        pos_image = images[idxB]\n",
    "        \n",
    "        # prepare positive pair and update images and labels lists respectively\n",
    "        pair_images.append([current_image, pos_image])\n",
    "        pair_labels.append([1])\n",
    "        \n",
    "        # grab the indicies for each of the class labels not equal to current label and \n",
    "        # randomly pick an image corresponding to a label not equal to current label\n",
    "        neg_idx = np.where(labels!=label)[0]\n",
    "        neg_image = images[np.random.choice(neg_idx)]\n",
    "        \n",
    "        # prepare a negative pair of images and update our lists\n",
    "        pair_images.append([current_image, neg_image])\n",
    "        pair_labels.append([0])\n",
    "        \n",
    "    return (np.array(pair_images), np.array(pair_labels))\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    # unpack vectors into seperate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    \n",
    "    # compute the sum of squared distances between vectors\n",
    "    sum_squared = K.sum(K.square(featsA - featsB), axis = 1, keepdims=True)\n",
    "    \n",
    "    # return the euclidean distance between vectors\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "def plot_training(H, plot_path):\n",
    "    # construct a plot that plots and saves training history\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(H.history['loss'], label='train_loss')\n",
    "    plt.plot(H.history['val_loss'], label='val_loss')\n",
    "    plt.plot(H.history['accuracy'], label='train_acc')\n",
    "    plt.plot(H.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed99feb-844c-4c12-adf8-5d00e707a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrastlive_loss\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def constrastive_loss(y, preds, margin=1):\n",
    "    # explicitly cast the true class label data type to the predicted class label\n",
    "    # type (otherwise we run the riskof having two seperate data types, causing \n",
    "    # tensorflow to error out)\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    \n",
    "    # calculate the constrastive loss between true labels and predicted labels\n",
    "    squared_preds = K.square(preds)\n",
    "    squared_margin = K.square(K.maximum(margin-preds, 0))\n",
    "    loss = K.mean(y * squared_preds + (1 - y) * squared_margin)\n",
    "    \n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
