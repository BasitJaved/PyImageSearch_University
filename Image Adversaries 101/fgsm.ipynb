{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f983d74-a92d-40ce-a963-db12a6d132d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1230\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class SimpleCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize model with input shape\n",
    "        model = Sequential()\n",
    "        input_shape = (height, width, depth)\n",
    "        chan_dim = -1\n",
    "        \n",
    "        # first CONV=>RELU=>BN layer set\n",
    "        model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        \n",
    "        # Second CONV=>RELU=>BN layer set\n",
    "        model.add(Conv2D(64, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        \n",
    "        # First and only set of FC=>RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54708d75-d740-46e0-b5c7-ea27f9e7fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Adversarial image\n",
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_image_adversary(model, image, label, eps=2/255.0):\n",
    "    # cast the image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # record gradients\n",
    "    with tf.Gradient.Tape() as tape:\n",
    "        # explicitly indicate that our image should be tracked for growing gradients\n",
    "        tape.watch(image)\n",
    "        \n",
    "        # use model to make predictions on input image and compute loss\n",
    "        pred = model(image)\n",
    "        loss = MSE(label, pred)\n",
    "        \n",
    "    # calculate gradients of loss w.r.t image then compute sign of gradient\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    # construct the image adversary\n",
    "    adversary = (image + (signed_grad * eps)).numpy()\n",
    "    \n",
    "    return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e47c7c6-d143-4470-9b6b-b7c04f99f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training Model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 19s 317us/sample - loss: 0.1982 - accuracy: 0.9407 - val_loss: 0.0572 - val_accuracy: 0.9823\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0757 - accuracy: 0.9770 - val_loss: 0.0513 - val_accuracy: 0.9841\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0572 - accuracy: 0.9821 - val_loss: 0.0460 - val_accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.0535 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.0466 - val_accuracy: 0.9871\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0337 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0299 - accuracy: 0.9907 - val_loss: 0.0527 - val_accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0558 - val_accuracy: 0.9834\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0449 - val_accuracy: 0.9861\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0402 - val_accuracy: 0.9882\n",
      "[INFO] loss: 0.0402, accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# load mnist dataset and scale the pixel values to range [0, 1]\n",
    "print('[INFO] loading MNIST dataset...')\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "# add a chennel dimension to images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "# one hot encode labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "# initialize optimizer and model\n",
    "print('[INFO] Compiling model...')\n",
    "opt = Adam(lr=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# train simple CNN on MNIST\n",
    "print('[INFO] Training Model...')\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, \n",
    "          epochs=10, verbose=1)\n",
    "\n",
    "# make predictions on testing set for model trained on non-adversarial images\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d68d5-2934-40b2-b926-7f3ca88a4d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
