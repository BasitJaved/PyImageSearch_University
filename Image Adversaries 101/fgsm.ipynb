{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f983d74-a92d-40ce-a963-db12a6d132d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class SimpleCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize model with input shape\n",
    "        model = Sequential()\n",
    "        input_shape = (height, width, depth)\n",
    "        chan_dim = -1\n",
    "        \n",
    "        # first CONV=>RELU=>BN layer set\n",
    "        model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        \n",
    "        # Second CONV=>RELU=>BN layer set\n",
    "        model.add(Conv2D(64, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        \n",
    "        # First and only set of FC=>RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54708d75-d740-46e0-b5c7-ea27f9e7fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Adversarial image\n",
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_image_adversary(model, image, label, eps=2/255.0):\n",
    "    # cast the image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # record gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # explicitly indicate that our image should be tracked for growing gradients\n",
    "        tape.watch(image)\n",
    "        \n",
    "        # use model to make predictions on input image and compute loss\n",
    "        pred = model(image)\n",
    "        loss = MSE(label, pred)\n",
    "        \n",
    "    # calculate gradients of loss w.r.t image then compute sign of gradient\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    # construct the image adversary\n",
    "    adversary = (image + (signed_grad * eps)).numpy()\n",
    "    \n",
    "    return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e47c7c6-d143-4470-9b6b-b7c04f99f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Training Model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.1995 - accuracy: 0.9404 - val_loss: 0.0671 - val_accuracy: 0.9797\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0792 - accuracy: 0.9758 - val_loss: 0.0525 - val_accuracy: 0.9834\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0543 - accuracy: 0.9833 - val_loss: 0.0431 - val_accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.0849 - val_accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0416 - accuracy: 0.9867 - val_loss: 0.0376 - val_accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0489 - val_accuracy: 0.9846\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0258 - accuracy: 0.9918 - val_loss: 0.0363 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0397 - val_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.0509 - val_accuracy: 0.9860\n",
      "[INFO] loss: 0.0509, accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# load mnist dataset and scale the pixel values to range [0, 1]\n",
    "print('[INFO] loading MNIST dataset...')\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "# add a chennel dimension to images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "# one hot encode labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "# initialize optimizer and model\n",
    "print('[INFO] Compiling model...')\n",
    "opt = Adam(lr=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# train simple CNN on MNIST\n",
    "print('[INFO] Training Model...')\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, \n",
    "          epochs=10, verbose=1)\n",
    "\n",
    "# make predictions on testing set for model trained on non-adversarial images\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927d68d5-2934-40b2-b926-7f3ca88a4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversary\n",
    "# loop over sample of images\n",
    "for i in np.random.choice(np.arange(0, len(testX)), size=(10,)):\n",
    "    # grab current image and label\n",
    "    image = testX[i]\n",
    "    label = testY[i]\n",
    "    \n",
    "    # generate an image adversary for current image and make a prediction on adversary\n",
    "    adversary = generate_image_adversary(model, image.reshape(1,28,28,1), \n",
    "                                         label, eps=0.1)\n",
    "    pred = model.predict(adversary)\n",
    "    \n",
    "    # scale both original image and adversary to range [0, 255] and convert them to\n",
    "    # an unsigned 8-bit integers\n",
    "    adversary = adversary.reshape((28, 28))*255\n",
    "    adversary = np.clip(adversary, 0, 255).astype('uint8')\n",
    "    image = image.reshape((28, 28))*255\n",
    "    image = image.astype('uint8')\n",
    "    \n",
    "    # convert image and adversary from gray scale to three channel to display\n",
    "    image = np.dstack([image]*3)\n",
    "    adversary = np.dstack([adversary]*3)\n",
    "    \n",
    "    # resize both so we can better visualize them\n",
    "    image = cv.resize(image, (96, 96))\n",
    "    adversary = cv.resize(adversary, (96, 96))\n",
    "    \n",
    "    # determine the label for both original image and adversarial image\n",
    "    image_pred = label.argmax()\n",
    "    adversary_pred = pred[0].argmax()\n",
    "    color = (0, 255, 0)\n",
    "    \n",
    "    if image_pred != adversary_pred:\n",
    "        color = (0, 0, 255)\n",
    "        \n",
    "    # draw predictions on respective output images\n",
    "    cv.putText(image, str(image_pred), (2, 25), cv.FONT_HERSHEY_SIMPLEX, \n",
    "               0.95, (0, 255, 0), 2)\n",
    "    cv.putText(adversary, str(adversary_pred), (2, 25), cv.FONT_HERSHEY_SIMPLEX, \n",
    "               0.95, color, 2)\n",
    "    \n",
    "    # stack both images horizontally and display them\n",
    "    output = np.hstack([image, adversary])\n",
    "    cv.imshow('FGSM Adversarial Images', output)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c5462-3d16-4e11-bdcf-7f49ed0e040b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
