{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_adversarial_defense.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aWu_sZHmNvv7"
      },
      "outputs": [],
      "source": [
        "#Simple CNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class SimpleCNN:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # initialize model with input shape\n",
        "        model = Sequential()\n",
        "        input_shape = (height, width, depth)\n",
        "        chan_dim = -1\n",
        "        \n",
        "        # first CONV=>RELU=>BN layer set\n",
        "        model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=chan_dim))\n",
        "        \n",
        "        # Second CONV=>RELU=>BN layer set\n",
        "        model.add(Conv2D(64, (3,3), strides=(2,2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=chan_dim))\n",
        "        \n",
        "        # First and only set of FC=>RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "        \n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation('softmax'))\n",
        "        \n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Adversarial image\n",
        "from tensorflow.keras.losses import MSE\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_image_adversary(model, image, label, eps=2/255.0):\n",
        "    # cast the image\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    \n",
        "    # record gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        # explicitly indicate that our image should be tracked for growing gradients\n",
        "        tape.watch(image)\n",
        "        \n",
        "        # use model to make predictions on input image and compute loss\n",
        "        pred = model(image)\n",
        "        loss = MSE(label, pred)\n",
        "        \n",
        "    # calculate gradients of loss w.r.t image then compute sign of gradient\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    \n",
        "    # construct the image adversary\n",
        "    adversary = (image + (signed_grad * eps)).numpy()\n",
        "    \n",
        "    return adversary"
      ],
      "metadata": {
        "id": "PEtPCYtdN0JA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating adversary images batch\n",
        "import numpy as np\n",
        "\n",
        "def generate_adversarial_batch(model, total, images, labels, dims, eps=0.01):\n",
        "    # unpack image dimensions into convienence variables\n",
        "    (h, w, c) = dims\n",
        "    \n",
        "    # since we are constructing a data generator here so we need to loop indefinitely\n",
        "    while True:\n",
        "        \n",
        "        # initialize our preturbed images and labels\n",
        "        preturbed_images = []\n",
        "        preturbed_labels = []\n",
        "        \n",
        "        # randomly sample indexes (without replacement) from input data\n",
        "        idx = np.random.choice(range(0, len(images)), size=total, replace=False)\n",
        "            \n",
        "        # loop over the indexes\n",
        "        for i in idx:\n",
        "                \n",
        "            # grab current image and label\n",
        "            image = images[i]\n",
        "            label = labels[i]\n",
        "                \n",
        "            # generate an adversarial image\n",
        "            adversary = generate_image_adversary(model, image.reshape(1, h, w, c),\n",
        "                                                    label, eps)\n",
        "                \n",
        "            # update preturbed images and label lists\n",
        "            preturbed_images.append(adversary.reshape(h, w, c))\n",
        "            preturbed_labels.append(label)\n",
        "                \n",
        "        #yield preturbed images and labels\n",
        "        yield (np.array(preturbed_images), np.array(preturbed_labels))"
      ],
      "metadata": {
        "id": "3w--8wORN1c2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "# load mnist dataset and scale the pixel values to range [0, 1]\n",
        "print('[INFO] loading MNIST dataset...')\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "# add a chennel dimension to images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "# one hot encode labels\n",
        "trainY = to_categorical(trainY, 10)\n",
        "testY = to_categorical(testY, 10)\n",
        "\n",
        "# initialize optimizer and model\n",
        "print('[INFO] Compiling model...')\n",
        "opt = Adam(lr=1e-3)\n",
        "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# train simple CNN on MNIST\n",
        "print('[INFO] Training Model...')\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, \n",
        "          epochs=20, verbose=1)\n",
        "\n",
        "# make predictions on testing set for model trained on non-adversarial images\n",
        "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRevloUCN-C3",
        "outputId": "e6b42089-db63-4275-9704-9e8dd84107c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "[INFO] Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Training Model...\n",
            "Epoch 1/20\n",
            "938/938 [==============================] - 21s 6ms/step - loss: 0.2019 - accuracy: 0.9397 - val_loss: 0.0655 - val_accuracy: 0.9793\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0760 - accuracy: 0.9771 - val_loss: 0.0458 - val_accuracy: 0.9851\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.0441 - val_accuracy: 0.9850\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.0345 - val_accuracy: 0.9878\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.0376 - val_accuracy: 0.9874\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.0482 - val_accuracy: 0.9848\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0348 - val_accuracy: 0.9877\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0373 - val_accuracy: 0.9885\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0345 - val_accuracy: 0.9891\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0500 - val_accuracy: 0.9853\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0366 - val_accuracy: 0.9891\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0335 - val_accuracy: 0.9901\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0360 - val_accuracy: 0.9892\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0386 - val_accuracy: 0.9888\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0379 - val_accuracy: 0.9901\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0417 - val_accuracy: 0.9879\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0375 - val_accuracy: 0.9893\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0409 - val_accuracy: 0.9895\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0401 - val_accuracy: 0.9890\n",
            "[INFO] loss: 0.0401, accuracy: 0.9890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on adversarial images\n",
        "\n",
        "# generate a set of adversarial from our test set\n",
        "print('[INFO] generating adversarial from our test set')\n",
        "(advX, advY) = next(generate_adversarial_batch(model, len(testX), testX, testY, \n",
        "                                               (28, 28, 1), eps=0.1))\n",
        "\n",
        "# re-evaluate model on adversarial images\n",
        "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
        "print('[INFO] adversarial testing images:')\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')\n",
        "\n",
        "# since accuracy has dropped on the adversarial images we will fine-tune our model \n",
        "#on the adversarial images\n",
        "# lower learning rate and re-compile model so we can fine tune it on adversairal images\n",
        "print('[INFO] re-compiling model...')\n",
        "opt = Adam(lr = 1e-4)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# fine tuning model on adversarial images\n",
        "print('[INFO] fine-tuning network on adversarial images...')\n",
        "model.fit(advX, advY, batch_size=64, epochs=15, verbose=1)\n",
        "\n",
        "\n",
        "# now that our model is fine tuned we should evaluate it on test set (non-adversarial)\n",
        "# to check if performance has degraded\n",
        "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
        "print('')\n",
        "print('[INFO] testing on normal images after fine-tuning:')\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')\n",
        "\n",
        "# final evaluation of model on adversarial images\n",
        "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
        "print('[INFO] testing on adversarial images after fine-tuning:')\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XguRAUBfN_nL",
        "outputId": "d574bed5-f59d-4262-f247-d4b20c990c7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] generating adversarial from our test set\n",
            "[INFO] adversarial testing images:\n",
            "[INFO] loss: 13.0508, accuracy: 0.0166\n",
            "[INFO] re-compiling model...\n",
            "[INFO] fine-tuning network on adversarial images...\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 5ms/step - loss: 8.6952 - accuracy: 0.2295\n",
            "Epoch 2/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 2.9628 - accuracy: 0.6119\n",
            "Epoch 3/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.3841 - accuracy: 0.7761\n",
            "Epoch 4/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.8605 - accuracy: 0.8509\n",
            "Epoch 5/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.8919\n",
            "Epoch 6/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3980 - accuracy: 0.9218\n",
            "Epoch 7/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3077 - accuracy: 0.9381\n",
            "Epoch 8/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2365 - accuracy: 0.9508\n",
            "Epoch 9/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1817 - accuracy: 0.9590\n",
            "Epoch 10/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1412 - accuracy: 0.9659\n",
            "Epoch 11/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.9720\n",
            "Epoch 12/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9767\n",
            "Epoch 13/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0769 - accuracy: 0.9802\n",
            "Epoch 14/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 0.9833\n",
            "Epoch 15/15\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0515 - accuracy: 0.9847\n",
            "\n",
            "[INFO] testing on normal images after fine-tuning:\n",
            "[INFO] loss: 0.0288, accuracy: 0.9909\n",
            "[INFO] testing on adversarial images after fine-tuning:\n",
            "[INFO] loss: 0.0270, accuracy: 0.9935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V8NgdWp-Ot5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}