{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_mixed_adversarial_defense.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrvE6wfOQEVB"
      },
      "outputs": [],
      "source": [
        "#Simple CNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class SimpleCNN:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # initialize model with input shape\n",
        "        model = Sequential()\n",
        "        input_shape = (height, width, depth)\n",
        "        chan_dim = -1\n",
        "        \n",
        "        # first CONV=>RELU=>BN layer set\n",
        "        model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=input_shape))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=chan_dim))\n",
        "        \n",
        "        # Second CONV=>RELU=>BN layer set\n",
        "        model.add(Conv2D(64, (3,3), strides=(2,2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization(axis=chan_dim))\n",
        "        \n",
        "        # First and only set of FC=>RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "        \n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation('softmax'))\n",
        "        \n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Adversarial image using FGSM\n",
        "from tensorflow.keras.losses import MSE\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_image_adversary(model, image, label, eps=2/255.0):\n",
        "    # cast the image\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    \n",
        "    # record gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        # explicitly indicate that our image should be tracked for growing gradients\n",
        "        tape.watch(image)\n",
        "        \n",
        "        # use model to make predictions on input image and compute loss\n",
        "        pred = model(image)\n",
        "        loss = MSE(label, pred)\n",
        "        \n",
        "    # calculate gradients of loss w.r.t image then compute sign of gradient\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    \n",
        "    # construct the image adversary\n",
        "    adversary = (image + (signed_grad * eps)).numpy()\n",
        "    \n",
        "    return adversary"
      ],
      "metadata": {
        "id": "OEVCtuZoR6Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating images batches (normal+adversarial)\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "# generating adversary images batch\n",
        "def generate_adversarial_batch(model, total, images, labels, dims, eps=0.01):\n",
        "    # unpack image dimensions into convienence variables\n",
        "    (h, w, c) = dims\n",
        "    \n",
        "    # since we are constructing a data generator here so we need to loop indefinitely\n",
        "    while True:\n",
        "        \n",
        "        # initialize our preturbed images and labels\n",
        "        preturbed_images = []\n",
        "        preturbed_labels = []\n",
        "        \n",
        "        # randomly sample indexes (without replacement) from input data\n",
        "        idxs = np.random.choice(range(0, len(images)), size=total, replace=False)\n",
        "            \n",
        "        # loop over the indexes\n",
        "        for i in idxs:\n",
        "                \n",
        "            # grab current image and label\n",
        "            image = images[i]\n",
        "            label = labels[i]\n",
        "                \n",
        "            # generate an adversarial image\n",
        "            adversary = generate_image_adversary(model, image.reshape(1, h, w, c),\n",
        "                                                    label, eps)\n",
        "                \n",
        "            # update preturbed images and label lists\n",
        "            preturbed_images.append(adversary.reshape(h, w, c))\n",
        "            preturbed_labels.append(label)\n",
        "                \n",
        "        #yield preturbed images and labels\n",
        "        yield (np.array(preturbed_images), np.array(preturbed_labels))\n",
        "\n",
        "# generating mixed images batch\n",
        "def generate_mixed_adversarial_batch(model, total, images, labels, dims, eps=0.01, split=0.5):\n",
        "  # unpack image dimensions into convienence variables\n",
        "  (h, w, c) = dims\n",
        "\n",
        "  #compute the total number of training images to keep along with the number of adversarial images \n",
        "  # to generate\n",
        "  total_normal = int(total*split)\n",
        "  total_adv = int(total * (1 - split))\n",
        "\n",
        "  # since we are constructing a data generator so we need to loop indefinatly\n",
        "  while True:\n",
        "\n",
        "    # randomly sample the indexes (without replacement) from the data and thenuse those indexes to \n",
        "    # sample our normal images and labels\n",
        "    idxs = np.random.choice(range(0, len(images)), size=total_normal, replace=False)\n",
        "    mixed_images = images[idxs]\n",
        "    mixed_labels = labels[idxs]\n",
        "\n",
        "    # again randomly sample indexes from the input data, this time to construct our adversarial \n",
        "    # images\n",
        "    idxs = np.random.choice(range(0, len(images)), size=total_adv, replace=False)\n",
        "    \n",
        "    # loop over the indexes\n",
        "    for i in idxs:\n",
        "      \n",
        "      # grab current image and label, then use that data to generate adversarial example\n",
        "      image = images[i]\n",
        "      label = labels[i]\n",
        "      adversary = generate_image_adversary(model, image.reshape(1, h, w, c), label, eps=eps)\n",
        "\n",
        "      # update mixed images and labels list\n",
        "      mixed_images = np.vstack([mixed_images, adversary])\n",
        "      mixed_labels = np.vstack([mixed_labels, label])\n",
        "\n",
        "    # shuffle images and labels\n",
        "    (mixed_images, mixed_labels) = shuffle(mixed_images, mixed_labels)\n",
        "\n",
        "    # yield the mixed images and labels to calling function\n",
        "    yield (mixed_images, mixed_labels)"
      ],
      "metadata": {
        "id": "V8W12IhRSJjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "# load mnist dataset and scale the pixel values to range [0, 1]\n",
        "print('[INFO] loading MNIST dataset...')\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "# add a chennel dimension to images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "# one hot encode labels\n",
        "trainY = to_categorical(trainY, 10)\n",
        "testY = to_categorical(testY, 10)\n",
        "\n",
        "# initialize optimizer and model\n",
        "print('[INFO] Compiling model...')\n",
        "opt = Adam(lr=1e-3)\n",
        "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# train simple CNN on MNIST\n",
        "print('[INFO] Training Model...')\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, \n",
        "          epochs=20, verbose=1)\n",
        "\n",
        "# make predictions on testing set for model trained on non-adversarial images\n",
        "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2McNxmjWgyR",
        "outputId": "ef40ab1f-d32c-439f-e9b4-41e49188d7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "[INFO] Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Training Model...\n",
            "Epoch 1/20\n",
            "938/938 [==============================] - 21s 6ms/step - loss: 0.1937 - accuracy: 0.9413 - val_loss: 0.0615 - val_accuracy: 0.9795\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0806 - accuracy: 0.9752 - val_loss: 0.0460 - val_accuracy: 0.9842\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.0390 - val_accuracy: 0.9871\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.0394 - val_accuracy: 0.9858\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 0.0408 - val_accuracy: 0.9869\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.0382 - val_accuracy: 0.9880\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0377 - val_accuracy: 0.9888\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0356 - val_accuracy: 0.9897\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0445 - val_accuracy: 0.9873\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0407 - val_accuracy: 0.9882\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0355 - val_accuracy: 0.9905\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0394 - val_accuracy: 0.9891\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0476 - val_accuracy: 0.9882\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0439 - val_accuracy: 0.9881\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0431 - val_accuracy: 0.9895\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.0395 - val_accuracy: 0.9908\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0404 - val_accuracy: 0.9896\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.0445 - val_accuracy: 0.9904\n",
            "[INFO] loss: 0.0445, accuracy: 0.9904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on adversarial images\n",
        "\n",
        "# generate a set of adversarial from our test set\n",
        "print('[INFO] generating adversarial from our test set')\n",
        "(advX, advY) = next(generate_adversarial_batch(model, len(testX), testX, testY, \n",
        "                                               (28, 28, 1), eps=0.1))\n",
        "\n",
        "# re-evaluate model on adversarial images\n",
        "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
        "print('[INFO] adversarial testing images:')\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')\n",
        "\n",
        "# since accuracy has dropped on the adversarial images we will fine-tune our model \n",
        "#on the adversarial images\n",
        "# lower learning rate and re-compile model such that we can fine tune it on the mixed batches of \n",
        "# normal images and dynamically generated adverserial images\n",
        "print('[INFO] re-compiling model...')\n",
        "opt = Adam(lr = 1e-4)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# initialize our data generator to create data batches containing a mix of both normal images and\n",
        "# adversarial images\n",
        "print('[INFO] creating mixed data generator')\n",
        "data_gen = generate_mixed_adversarial_batch(model, 64, trainX, trainY, (28, 28, 1), \n",
        "                                            eps=0.1, split=0.5)\n",
        "\n",
        "# train model on mixed images\n",
        "print('[INFO] Training network on dynamic mixed images...')\n",
        "model.fit(data_gen, steps_per_epoch=len(trainX)//64, epochs=15, verbose=1)\n",
        "\n",
        "\n",
        "# now that our model is re-trained we should evaluate it on test set (non-adversarial)\n",
        "# to check if performance has degraded\n",
        "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
        "print('')\n",
        "print('[INFO] testing on normal images after re-training:')\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')\n",
        "\n",
        "# final evaluation of model on adversarial images\n",
        "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
        "print('[INFO] testing on adversarial images after re-training:')\n",
        "print(f'[INFO] loss: {loss:.4f}, accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYY94hQWXMKY",
        "outputId": "89cc407e-ff4d-4869-8579-5caef1c9f1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] generating adversarial from our test set\n",
            "[INFO] adversarial testing images:\n",
            "[INFO] loss: 14.3745, accuracy: 0.0141\n",
            "[INFO] re-compiling model...\n",
            "[INFO] creating mixed data generator\n",
            "[INFO] Training network on dynamic mixed images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "937/937 [==============================] - 292s 312ms/step - loss: 1.6165 - accuracy: 0.7545\n",
            "Epoch 2/15\n",
            "937/937 [==============================] - 293s 313ms/step - loss: 0.4162 - accuracy: 0.8808\n",
            "Epoch 3/15\n",
            "937/937 [==============================] - 293s 312ms/step - loss: 0.2842 - accuracy: 0.9110\n",
            "Epoch 4/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.2247 - accuracy: 0.9300\n",
            "Epoch 5/15\n",
            "937/937 [==============================] - 291s 310ms/step - loss: 0.1975 - accuracy: 0.9369\n",
            "Epoch 6/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.1713 - accuracy: 0.9453\n",
            "Epoch 7/15\n",
            "937/937 [==============================] - 291s 310ms/step - loss: 0.1589 - accuracy: 0.9486\n",
            "Epoch 8/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.1451 - accuracy: 0.9529\n",
            "Epoch 9/15\n",
            "937/937 [==============================] - 292s 312ms/step - loss: 0.1319 - accuracy: 0.9566\n",
            "Epoch 10/15\n",
            "937/937 [==============================] - 292s 312ms/step - loss: 0.1222 - accuracy: 0.9601\n",
            "Epoch 11/15\n",
            "937/937 [==============================] - 292s 311ms/step - loss: 0.1154 - accuracy: 0.9621\n",
            "Epoch 12/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.1078 - accuracy: 0.9650\n",
            "Epoch 13/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.1012 - accuracy: 0.9665\n",
            "Epoch 14/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.0911 - accuracy: 0.9698\n",
            "Epoch 15/15\n",
            "937/937 [==============================] - 291s 311ms/step - loss: 0.0931 - accuracy: 0.9698\n",
            "\n",
            "[INFO] testing on normal images after re-training:\n",
            "[INFO] loss: 0.0265, accuracy: 0.9916\n",
            "[INFO] testing on adversarial images after re-training:\n",
            "[INFO] loss: 0.0741, accuracy: 0.9760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KXXeNI-4ZNsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}