{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbee61a-68f7-4867-80a3-f442b2bb592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Base path of dataset\n",
    "dataset_path = os.path.join('seg', 'train')\n",
    "\n",
    "# define path to images and masks dataset\n",
    "image_dataset_path = os.path.join(dataset_path, 'images')\n",
    "mask_dataset_path = os.path.join(dataset_path, 'masks')\n",
    "\n",
    "# define the test split\n",
    "test_split = 0.15\n",
    "\n",
    "# determine the device to be used for training and evaluation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# determine if we will be pinning memory during data loading\n",
    "pin_memory = True if device == 'cuda' else False\n",
    "\n",
    "# determine the number of channels in input, number of classes and number of levels in u-net model\n",
    "num_channels = 1\n",
    "num_classes = 1\n",
    "num_levels = 3\n",
    "\n",
    "# initialize the learning rate, number of epochs to train for and batch size\n",
    "init_lr = 0.001\n",
    "num_epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "# define input image dimensions\n",
    "input_image_width = 128\n",
    "input_image_height = 128\n",
    "\n",
    "# define threshold to filter weak predictions\n",
    "threshold = 0.5\n",
    "\n",
    "#define path to base output directory\n",
    "base_output = 'output'\n",
    "\n",
    "# define path to output serialized model, model training plot and testing image paths\n",
    "model_path = os.path.join(base_output, 'unet_tgs_salt.pth')\n",
    "plot_path = os.path.sep.join([base_output, 'unet_tgs_salt.png'])\n",
    "test_path = os.path.sep.join([base_output, 'test_paths.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9c78da-3c4b-44c8-abc0-8811cd017c0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\B84145~1\\AppData\\Local\\Temp/ipykernel_9668/2922052179.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSegmentationDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "from torch.utils.data import Dataset\n",
    "import cv2 as cv\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transforms):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return the number of total samples in dataset\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __get_item__(self, idx):\n",
    "        # grab image path from current index\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        # load image from disk, swap its channels from BGR to RGB and read the associated mask from disk in grayscale mode\n",
    "        image = cv.imread(image_path)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        mask = cv.imread(self.mask_paths[idx], 0)\n",
    "        \n",
    "        # check to see if we are applying any transforms\n",
    "        if self.transforms is not None:\n",
    "            # apply transforms to both image and mask\n",
    "            image = self.transforms(image)\n",
    "            mask = self.transforms(mask)\n",
    "            \n",
    "        # return image and mask\n",
    "        return (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bb1fc-3524-4722-83ac-f0dff866c1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
